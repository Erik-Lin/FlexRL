algo: "ppo"
env: "mazeEnv"
train: True  
episodes: 200
test_episodes: 10
update_interval: 20
max_steps: 200
batch_size: 32
discount: 0.99
seed: 0
device: "cpu"
render: false
capacity: 5000
K_epochs : 10               # update policy for K epochs in one PPO update
eps_clip : 0.2          # clip parameter for PPO
gamma : 0.99            # discount factor
lr_actor : 0.0003       # learning rate for actor network
lr_critic : 0.001       # learning rate for critic network
