algo: "ppo"
env: "mazeEnv"
device: "cpu"
draw_show : False
train: False  
episodes: 200
test_episodes: 10
max_steps: 200
batch_size: 32
hidden_dim : 128
seed: 0
render: false
capacity: 5000
K_epochs : 10               # update policy for K epochs in one PPO update
clip_param : 0.2          # clip parameter for PPO
max_grad_norm: 0.5
ppo_update_time: 10
gamma : 0.99            # discount factor
lr_actor : 0.0003       # learning rate for actor network
lr_critic : 0.001       # learning rate for critic network